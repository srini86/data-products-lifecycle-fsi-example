# Data Products for Financial Services

Build a production-ready **Retail Customer Churn Risk** data product on Snowflake â€” from data contract to governed, tested, deployed table.

ğŸ“ **Blog Post:** [Building Enterprise Grade Data Products for FSI â€” Moving from Strategy to Tactics](https://datadonutz.medium.com/building-regulatory-grade-data-products-on-snowflake-for-fsi-938895e25e35)

---

## Data Product Lifecycle

<p align="center">
  <img src="00_setup/data-product-lifecycle.png" alt="Data Product Lifecycle" width="700"/>
</p>

| Stage | What Happens | Folder |
|-------|-------------|--------|
| **Discover** | Event storms identify candidate data products | `01_discover/` |
| **Design** | Canvas â†’ machine-readable data contract | `02_design/` |
| **Deliver** | Generate code, deploy, test | `03_deliver/` |
| **Operate** | Monitor SLAs, quality, usage | `04_operate/` |
| **Refine** | Evolve with new features and versions | `05_refine/` |

---

## Architecture: LLM vs Agent

This repo provides two approaches. Both start from the same data contract and produce the same table.

**Streamlit â€” LLM (single-pass)**

```
Contract YAML â”€â”€â–º Cortex LLM â”€â”€â–º Generated SQL
                  (one prompt)    schema.yml      â”€â”€â–º Manual deploy
                                  masking.sql          via Snowsight
                                  dmf_setup.sql
```

**Cortex Code â€” Agent (multi-skill orchestration)**

```
Contract YAML â”€â”€â–º Cortex Code Agent
                       â”‚
                  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚         7 Skills             â”‚
                  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                  â”‚  â”‚model-sqlâ”‚  â”‚ schema-ymlâ”‚ â”‚     prompt.md
                  â”‚  â”‚  (AI)   â”‚  â”‚ (template)â”‚ â”‚    (guardrails)
                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚        â”‚
                  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚        â–¼
                  â”‚  â”‚masking  â”‚  â”‚ dmf-setup â”‚ â”‚   Plan â–º Generate
                  â”‚  â”‚(templateâ”‚  â”‚ (template)â”‚ â”‚   â–º Validate â–º Deploy
                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â–º Test â–º Learn
                  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚        â”‚
                  â”‚  â”‚test-gen â”‚  â”‚ deployer  â”‚ â”‚        â–¼
                  â”‚  â”‚(templateâ”‚  â”‚ (snow CLI)â”‚ â”‚   Error Playbook
                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  (lessons persist)
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| | **Streamlit (LLM)** | **Cortex Code (Agent)** |
|---|---|---|
| **Invocations** | 1 prompt â†’ 1 response | N skills â†’ N artifacts, iteratively |
| **AI usage** | LLM generates SQL; templates handle rest | LLM generates SQL only; templates handle 6 of 7 |
| **Memory** | Stateless | `prompt.md` + Error Playbook persist across sessions |
| **Governance** | Implicit in app code | Explicit in `prompt.md` (forbidden patterns, naming rules) |
| **Iteration** | Re-run entire generation | Re-run individual skill |

---

## How to Use This Repo

### Step 1: Setup Environment

- Clone the repo:
  ```bash
  git clone https://github.com/sfc-gh-skuppusamy/data-products-code-sample
  ```
- Open `00_setup/setup.sql` in Snowsight
- Run Steps 1â€“4 to create database, schemas, and sample data
- Run Step 5 to create the Streamlit app (only needed for 3a)
- Run Step 6 to verify all assets

### Step 2: Design Your Data Contract

- An example contract is provided at `02_design/_example/churn_risk_data_contract.yaml` â€” use it as a reference
- To create your own, provide CoCo with your Data Product Canvas (or requirements) and ask it to generate a contract:
  ```
  "Generate an ODCS v2.2 data contract for <your data product>. 
   Use 02_design/_example/churn_risk_data_contract.yaml as a reference for structure."
  ```
- The contract defines schema, quality rules, masking policies, and SLAs
- It is the **single input** that drives all code generation in Step 3

### Step 3: Generate & Deploy Data Product

Choose **3a** or **3b**:

#### Step 3a: Streamlit App

- Open Snowsight â†’ Projects â†’ Streamlit â†’ `dbt_code_generator`
- Paste the contract YAML or load from stage
- Click **Generate All Outputs** â€” produces:
  - `retail_customer_churn_risk.sql` (dbt model)
  - `schema.yml` (tests + docs)
  - `masking_policies.sql`
- Create a dbt Project in Snowsight â†’ add model + schema â†’ Compile â†’ Run
- Run `masking_policies.sql` in a worksheet
- Run `03_deliver/_example/02_data_quality_dmf.sql` for DMF setup
- Run `03_deliver/_example/03_semantic_view_marketplace.sql` for semantic view
- Sample outputs: `03_deliver/_example/`

#### Step 3b: Cortex Code

- Start Cortex Code in the repo directory â€” skills auto-load from `.cortex/skills/`
- Use these prompts to walk through the lifecycle:
  1. `"Read the data contract at 02_design/_example/churn_risk_data_contract.yaml and generate a complete dbt project â€” model SQL, schema.yml, and tests"`
  2. `"Generate masking policies and DMF setup SQL based on the governance rules in the contract"`
  3. `"Generate monitoring and observability SQL â€” freshness SLAs, quality checks, usage tracking, and alerts"`
  4. `"Deploy the dbt project to Snowflake using snow dbt deploy and run it"`
  5. `"Validate the deployment â€” run tests, check row counts, verify masking is applied"`
- Full playbook: [`.cortex/guides/DATA_PRODUCT_PLAYBOOK.md`](.cortex/guides/DATA_PRODUCT_PLAYBOOK.md) â€” covers skills architecture, guardrails, and error playbook

### Step 4: Operate & Monitor

- If you used **Step 3a**, run `04_operate/_example/monitoring_observability.sql` manually in Snowsight
- If you used **Step 3b**, monitoring was generated in prompt 3 above
- What it covers:
  - Freshness SLAs and availability
  - Quality expectation status and masking verification
  - Usage by role/user and query patterns

### Step 5: Refine & Evolve

- See `05_refine/_example/churn_risk_data_contract_v2.yaml` for an evolved contract (adds CLV, vulnerability indicator)
- Run `05_refine/_example/evolution_example.sql` for schema evolution patterns

### Cleanup

- Run `06_cleanup/cleanup.sql` to remove all demo resources

---

## Folder Structure

```
.cortex/
  â”œâ”€â”€ skills/capture-feedback/         # CoCo feedback skill
  â””â”€â”€ guides/                          # CoCo guides & prompts
        â”œâ”€â”€ DATA_PRODUCT_PLAYBOOK.md
        â””â”€â”€ TODO.md
00_setup/                              # Setup script + lifecycle diagram
01_discover/                           # Data product canvas
02_design/
  â”œâ”€â”€ README.md                        # Phase guide
  â”œâ”€â”€ data_contract_informs.png        # Contract-driven architecture diagram
  â””â”€â”€ _example/                        # FSI churn-risk example
        â””â”€â”€ churn_risk_data_contract.yaml
03_deliver/
  â”œâ”€â”€ README.md                        # Phase guide
  â”œâ”€â”€ 01_code_generator_service.py     # Streamlit code generator app
  â”œâ”€â”€ code_generation_flow.png
  â”œâ”€â”€ cortex_code_skills_flow.png
  â””â”€â”€ _example/                        # FSI churn-risk generated outputs
        â”œâ”€â”€ dbt_project/               # Complete dbt project
        â”œâ”€â”€ masking_policies.sql
        â”œâ”€â”€ dmf_setup.sql
        â”œâ”€â”€ 02_data_quality_dmf.sql
        â”œâ”€â”€ 03_semantic_view_marketplace.sql
        â””â”€â”€ validate_deployment.sql
04_operate/
  â”œâ”€â”€ README.md                        # Phase guide
  â”œâ”€â”€ raci_template.md                 # Reusable RACI template
  â””â”€â”€ _example/
        â””â”€â”€ monitoring_observability.sql
05_refine/
  â”œâ”€â”€ README.md                        # Phase guide
  â””â”€â”€ _example/
        â”œâ”€â”€ churn_risk_data_contract_v2.yaml
        â””â”€â”€ evolution_example.sql
06_cleanup/                            # Cleanup script
prompt.md                              # CoCo standing rules (auto-read at session start)
```

---

> **Disclaimer:** This is a personal project for educational and demonstration purposes.
