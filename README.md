# Data Products for Financial Services

Build a production-ready **Retail Customer Churn Risk** data product on Snowflake ‚Äî complete with AI-generated dbt models, masking policies, semantic views, and data quality monitoring.

This repo provides **two patterns** for building the same data product from a data contract. Choose the one that fits your team.

üìù **Blog Post:** [Building Enterprise Grade Data Products for FSI ‚Äî Moving from Strategy to Tactics](https://datadonutz.medium.com/building-regulatory-grade-data-products-on-snowflake-for-fsi-938895e25e35) ‚Äî covers the data product blueprint in detail

---

## Overview: Data Product Lifecycle

This repository follows a 5-stage lifecycle for delivering data products:

<p align="center">
  <img src="00_setup/data-product-lifecycle.png" alt="Data Product Lifecycle" width="700"/>
</p>

| Stage | What Happens | Repo Folder |
|-------|--------------|-------------|
| **Discover** | Business event storms identify candidate data products | `01_discover/` |
| **Design** | Define specifications in a canvas, convert to a machine-readable data contract | `02_design/` |
| **Deliver** | Build data assets with code, metadata, and compute | `03_deliver/` |
| **Operate** | Monitor SLA, data quality, usage, and data drifts | `04_operate/` |
| **Refine** | Evolve with new features and versions | `05_refine/` |

---

## Two Patterns for Building Data Products

Both patterns start from the same data contract and produce the same data product. They differ in **how** code is generated and deployed.

| | **Pattern A: Streamlit App** | **Pattern B: Cortex Code** |
|---|---|---|
| **Interface** | Snowsight Streamlit UI | CLI / Terminal |
| **Code generation** | Paste contract into app, click Generate | Skills auto-generate from contract via prompts |
| **What gets generated** | dbt model SQL, schema.yml, masking policies | dbt model SQL, schema.yml, masking policies, DMFs, singular tests, deployment scripts |
| **Deployment** | Manual via Snowsight dbt Project + worksheets | `snow dbt deploy` + `snow dbt execute` |
| **Testing** | DMF setup via SQL script | 8 singular dbt tests + DMFs |
| **Governance** | Ad-hoc | `prompt.md` guardrails + Error Playbook |
| **Developer role** | Operator (copy-paste-run) | Reviewer (AI generates, you decide) |
| **Best for** | Quick demos, visual walkthroughs | Repeatable pipelines, team adoption, CI/CD |
| **Key files** | `03_deliver/01_dbt_generator_app.py` | `.cortex/skills/`, `PROMPT_INSTRUCTION_GUIDE.md` |

> Both patterns produce the same `RETAIL_CUSTOMER_CHURN_RISK` table with identical schema, masking, and quality rules.

### Architecture: LLM vs Agent

The two patterns represent two distinct AI architecture approaches for building data products from contracts.

**Pattern A ‚Äî LLM (Single-pass generation)**

```
Contract YAML ‚îÄ‚îÄ‚ñ∫ Cortex LLM ‚îÄ‚îÄ‚ñ∫ Generated SQL
                  (one prompt)    schema.yml      ‚îÄ‚îÄ‚ñ∫ Manual deploy
                                  masking.sql          via Snowsight
                                  dmf_setup.sql
```

One prompt, one response. The contract is parsed, the LLM generates transformation SQL, and templates produce the rest. No memory between runs. No feedback loop. No governance artifacts.

**Pattern B ‚Äî Agent (Multi-skill orchestration)**

```
Contract YAML ‚îÄ‚îÄ‚ñ∫ Cortex Code Agent
                       ‚îÇ
                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ         7 Skills             ‚îÇ
                  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
                  ‚îÇ  ‚îÇmodel-sql‚îÇ  ‚îÇ schema-yml‚îÇ ‚îÇ     prompt.md
                  ‚îÇ  ‚îÇ  (AI)   ‚îÇ  ‚îÇ (template)‚îÇ ‚îÇ    (guardrails)
                  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ        ‚îÇ
                  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ        ‚ñº
                  ‚îÇ  ‚îÇmasking  ‚îÇ  ‚îÇ dmf-setup ‚îÇ ‚îÇ   Plan ‚ñ∫ Generate
                  ‚îÇ  ‚îÇ(template‚îÇ  ‚îÇ (template)‚îÇ ‚îÇ   ‚ñ∫ Validate ‚ñ∫ Deploy
                  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ   ‚ñ∫ Test ‚ñ∫ Learn
                  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ        ‚îÇ
                  ‚îÇ  ‚îÇtest-gen ‚îÇ  ‚îÇ deployer  ‚îÇ ‚îÇ        ‚ñº
                  ‚îÇ  ‚îÇ(template‚îÇ  ‚îÇ (snow CLI)‚îÇ ‚îÇ   Error Playbook
                  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ  (lessons persist)
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

The agent breaks the problem into steps, invokes the right skill for each artifact, validates outputs, deploys, and captures errors as reusable knowledge. Governance is codified. Lessons persist across sessions.

| | **LLM (Pattern A)** | **Agent (Pattern B)** |
|---|---|---|
| **Invocations** | 1 prompt ‚Üí 1 response | N skills ‚Üí N artifacts, iteratively |
| **AI usage** | LLM generates SQL + templates handle rest | LLM generates SQL only; templates handle 6 of 7 artifacts |
| **Memory** | None ‚Äî stateless per run | `prompt.md` + Error Playbook persist across sessions |
| **Feedback loop** | None | Capture-feedback skill bakes lessons into guardrails |
| **Governance** | Implicit in app code | Explicit in `prompt.md` (forbidden patterns, naming rules) |
| **Iteration** | Re-run entire generation | Re-run individual skill |

---

## Common Setup (Both Patterns)

**Prerequisites:** The Discover and Design phases are assumed to be complete. Artefacts from these phases are available as the data product canvas (`01_discover/data_product_canvas.yaml`) and data contract (`02_design/churn_risk_data_contract.yaml`).

1. **Get the code** (choose one):
   - **Clone locally:**
     ```bash
     git clone https://github.com/sfc-gh-skuppusamy/data-products-code-sample
     ```
   - **From Snowsight:** Projects ‚Üí Worksheets ‚Üí Create from Git Repository

2. **Run setup script** ‚Äî Open `00_setup/setup.sql` in Snowsight:
   - Run **Steps 1‚Äì4** to create database, schemas, and sample data
   - Run **Step 5** to create the Streamlit app (only needed for Pattern A)
   - Run **Step 6** to verify all assets are created

After setup, choose your pattern below.

---

## Pattern A: Streamlit App

> **Use this pattern** for quick demos, visual walkthroughs, or when working entirely within Snowsight.

<p align="center">
  <img src="03_deliver/code_generation_flow.png" alt="Code Generation Flow" width="600"/>
</p>

### A1. Generate Data Product Code

1. Open the Streamlit app: Snowsight ‚Üí **Projects** ‚Üí **Streamlit** ‚Üí `dbt_code_generator`
2. Choose an input method:
   - **Paste YAML:** Copy contents of `02_design/churn_risk_data_contract.yaml` and paste
   - **Load from Stage:** Enter stage path and filename
3. Click **Generate All Outputs**
4. The app generates:
   - `retail_customer_churn_risk.sql` ‚Äî dbt model with transformation logic
   - `schema.yml` ‚Äî dbt schema with documentation and tests
   - `masking_policies.sql` ‚Äî Snowflake masking policies

> üí° **Sample outputs** are available at `03_deliver/generated_output_samples/` for reference.

### A2. Deploy Data Product

1. **Deploy dbt model:**
   - Create a **dbt Project** in Snowsight ‚Üí Add `retail_customer_churn_risk.sql` and `schema.yml` to the models folder ‚Üí **Compile** and **Run**
2. **Apply masking policies:**
   - Run `masking_policies.sql` in a Snowsight Worksheet
3. **Set up data quality rules:**
   - Run `03_deliver/02_data_quality_dmf.sql` ‚Äî Sets up Data Metric Functions with expectations from the contract
4. **Create Semantic View and Marketplace listing:**
   - Run `03_deliver/03_semantic_view_marketplace.sql`
   - ‚ö†Ô∏è **Before running:** Update `YOUR_ACCOUNT_NAME` and `your.email@company.com` with your values

### A3. Verify the Data Product

1. **Database Explorer:** Snowsight ‚Üí Data ‚Üí Databases ‚Üí `RETAIL_BANKING_DB` ‚Üí `DATA_PRODUCTS` ‚Üí `RETAIL_CUSTOMER_CHURN_RISK`
2. **Private Sharing:** Snowsight ‚Üí Catalog ‚Üí Internal Marketplace ‚Üí Search for "Retail Customer Churn Risk"

---

## Pattern B: Cortex Code

> **Use this pattern** for repeatable, contract-driven pipelines with built-in governance, testing, and feedback loops.

<p align="center">
  <img src="03_deliver/cortex_code_skills_flow.png" alt="Cortex Code Skills Flow" width="600"/>
</p>

### B1. Start Cortex Code

Open a terminal in the repo directory. Cortex Code auto-detects the `.cortex/skills/` folder and loads project-level skills.

```bash
cd data-products-lifecycle-fsi-example
cortex
```

### B2. Generate Data Product Code

Follow the **Prompt Instruction Guide** (`PROMPT_INSTRUCTION_GUIDE.md`) ‚Äî it walks through each lifecycle phase. Skills generate code from the data contract:

- **Transformation SQL** ‚Äî AI-generated from contract schema + derivation rules
- **schema.yml** ‚Äî Deterministic template from contract column definitions
- **Masking policies** ‚Äî Deterministic template from contract masking rules
- **DMF setup** ‚Äî Deterministic template from contract quality rules
- **Singular tests** ‚Äî Deterministic template from contract business rules

> **AI vs Template pattern:** Only transformation SQL uses Cortex AI. Everything else is deterministic ‚Äî same contract always produces same output.

### B3. Deploy Data Product

```bash
snow dbt deploy --project-name RETAIL_CHURN_RISK
snow dbt execute --project-name RETAIL_CHURN_RISK run
snow dbt execute --project-name RETAIL_CHURN_RISK test
```

Additional deployment scripts:
- `03_deliver/deploy_model.sql` ‚Äî Full deployment with table creation
- `03_deliver/masking_policies.sql` ‚Äî Apply masking policies
- `03_deliver/dmf_setup.sql` ‚Äî Configure Data Metric Functions
- `03_deliver/validate_deployment.sql` ‚Äî Run validation checks

### B4. Capture Feedback

At the end of a session, invoke the `capture-feedback` skill to update the Error Playbook and bake lessons into `prompt.md`:

```
$capture-feedback
```

### What's Included (Pattern B)

| Asset | Path | Purpose |
|-------|------|---------|
| **Prompt Instruction Guide** | `PROMPT_INSTRUCTION_GUIDE.md` | Reusable lifecycle playbook ‚Äî skills architecture, guardrails, error playbook |
| **Capture Feedback Skill** | `.cortex/skills/capture-feedback/` | Captures session errors into Error Playbook and `prompt.md` |
| **Skills Flow Diagram** | `03_deliver/cortex_code_skills_flow.png` | Visual: how 7 skills map to lifecycle phases |
| **Code Generator Service** | `03_deliver/01_code_generator_service.py` | Python service for contract-driven code generation |
| **dbt Singular Tests** | `03_deliver/dbt_project/tests/` | 8 data quality and business rule tests |
| **Deployment Scripts** | `03_deliver/deploy_model.sql`, `dmf_setup.sql`, `masking_policies.sql`, `validate_deployment.sql` | SQL scripts for deploying and validating |
| **Progress Tracker** | `TODO.md` | Checklist tracking all lifecycle phases |

### Key Concepts (Pattern B)

- **Contract-driven**: The data contract (`02_design/retail_churn_contract.yaml`) is the single source of truth for all generated code
- **AI vs Template**: Only transformation SQL uses Cortex AI; everything else is deterministic
- **Developer as reviewer**: Cortex Code generates 80% of the code; you make business decisions and review

> See `PROMPT_INSTRUCTION_GUIDE.md` for the complete guide including skills architecture, guardrails, and error playbook.

---

## Operate & Monitor (Both Patterns)

Once the data product is live, the focus shifts to running it well ‚Äî regardless of which pattern you used to build it.

Run in Snowsight:
- `04_operate/monitoring_observability.sql` ‚Äî Sets up ongoing monitoring for:
  - **Reliability:** Freshness SLAs, availability, data gaps
  - **Quality & Compliance:** Expectation status, masking verification, lineage
  - **Adoption & Impact:** Usage by role/user, query patterns, dependencies

---

## Folder Structure

```
‚îú‚îÄ‚îÄ .cortex/                                        ‚îÄ‚îÄ Pattern B
‚îÇ   ‚îî‚îÄ‚îÄ skills/
‚îÇ       ‚îî‚îÄ‚îÄ capture-feedback/                       # Feedback capture skill
‚îú‚îÄ‚îÄ 00_setup/                                       ‚îÄ‚îÄ Both
‚îÇ   ‚îú‚îÄ‚îÄ setup.sql                                   # One-click setup script
‚îÇ   ‚îî‚îÄ‚îÄ data-product-lifecycle.png                  # Lifecycle diagram
‚îú‚îÄ‚îÄ 01_discover/                                    ‚îÄ‚îÄ Both
‚îÇ   ‚îú‚îÄ‚îÄ data_product_canvas.png                     # Visual canvas
‚îÇ   ‚îî‚îÄ‚îÄ data_product_canvas.yaml                    # Machine-readable canvas
‚îú‚îÄ‚îÄ 02_design/                                      ‚îÄ‚îÄ Both
‚îÇ   ‚îú‚îÄ‚îÄ churn_risk_data_contract.yaml               # Data contract (Pattern A)
‚îÇ   ‚îú‚îÄ‚îÄ retail_churn_contract.yaml                  # ODCS v2.2 contract (Pattern B)
‚îÇ   ‚îî‚îÄ‚îÄ data_contract_informs.png                   # Contract-driven diagram
‚îú‚îÄ‚îÄ 03_deliver/                                     ‚îÄ‚îÄ Both
‚îÇ   ‚îú‚îÄ‚îÄ 01_dbt_generator_app.py                     # Streamlit app (Pattern A)
‚îÇ   ‚îú‚îÄ‚îÄ 01_code_generator_service.py                # Code generator (Pattern B)
‚îÇ   ‚îú‚îÄ‚îÄ 02_data_quality_dmf.sql                     # DMF setup (Pattern A)
‚îÇ   ‚îú‚îÄ‚îÄ 03_semantic_view_marketplace.sql            # Semantic view (Pattern A)
‚îÇ   ‚îú‚îÄ‚îÄ deploy_model.sql                            # Deployment script (Pattern B)
‚îÇ   ‚îú‚îÄ‚îÄ dmf_setup.sql                               # DMF setup (Pattern B)
‚îÇ   ‚îú‚îÄ‚îÄ masking_policies.sql                        # Masking policies (Pattern B)
‚îÇ   ‚îú‚îÄ‚îÄ validate_deployment.sql                     # Validation tests (Pattern B)
‚îÇ   ‚îú‚îÄ‚îÄ cortex_code_skills_flow.png                 # Skills diagram (Pattern B)
‚îÇ   ‚îú‚îÄ‚îÄ automted-data-pipeline.png                  # Pipeline diagram (Both)
‚îÇ   ‚îú‚îÄ‚îÄ code_generation_flow.png                    # AI vs template diagram (Both)
‚îÇ   ‚îú‚îÄ‚îÄ dbt_project/                                # dbt project (Both)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/                                 # Model SQL + schema.yml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tests/                                  # 8 singular tests (Pattern B)
‚îÇ   ‚îî‚îÄ‚îÄ generated_output_samples/                   # Sample outputs (Pattern A)
‚îú‚îÄ‚îÄ 04_operate/                                     ‚îÄ‚îÄ Both
‚îÇ   ‚îú‚îÄ‚îÄ monitoring_observability.sql                # Monitoring & alerts
‚îÇ   ‚îî‚îÄ‚îÄ raci_template.md                            # RACI matrix template
‚îú‚îÄ‚îÄ 05_refine/                                      ‚îÄ‚îÄ Both
‚îÇ   ‚îú‚îÄ‚îÄ churn_risk_data_contract_v2.yaml            # Evolved contract
‚îÇ   ‚îî‚îÄ‚îÄ evolution_example.sql                       # Schema evolution example
‚îú‚îÄ‚îÄ 06_cleanup/                                     ‚îÄ‚îÄ Both
‚îÇ   ‚îî‚îÄ‚îÄ cleanup.sql                                 # Remove all demo resources
‚îú‚îÄ‚îÄ PROMPT_INSTRUCTION_GUIDE.md                     # Lifecycle playbook (Pattern B)
‚îú‚îÄ‚îÄ TODO.md                                         # Progress tracker (Pattern B)
‚îî‚îÄ‚îÄ data-products-prompt.md                         # Original prompt (Pattern A)
```

---

## What Gets Created

| Resource | Name | Created By |
|----------|------|------------|
| Database | `RETAIL_BANKING_DB` | Setup (Both) |
| Warehouse | `DATA_PRODUCTS_WH` | Setup (Both) |
| Source Tables | `CUSTOMERS`, `ACCOUNTS`, `TRANSACTIONS`, `DIGITAL_ENGAGEMENT`, `COMPLAINTS` | Setup (Both) |
| Data Product | `RETAIL_CUSTOMER_CHURN_RISK` | Pattern A or B |
| Streamlit App | `dbt_code_generator` | Setup (Pattern A) |
| Semantic View | `retail_customer_churn_risk_sv` | Pattern A |
| DMFs | NULL_COUNT, DUPLICATE_COUNT, FRESHNESS, ROW_COUNT | Pattern A or B |

---

## Cleanup

Run `06_cleanup/cleanup.sql` to remove all demo resources.

---

> **Disclaimer:** This is a personal project for educational and demonstration purposes.
